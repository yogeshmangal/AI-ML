# AI & LLM Quick Reference

## Q1. What is LLM in brief?  
**LLM** stands for **Large Language Model**.  
An AI model trained on huge amounts of text data to understand and generate human-like language. It can answer questions, summarize, translate, write text, and chat.

---

## Q2. What is LangChain in brief?  
**LangChain** is a framework to build applications with LLMs by connecting them to external data, memory, tools, and defining workflows (chains).

---

## Q3. What is LangGraph?  
**LangGraph** is a framework built on LangChain for creating stateful, multi-step workflows structured as a graph of nodes and edges. It enables complex decision-making and branching logic with LLM agents.

---

## Q4. What is RAG?  
**RAG** (Retrieval-Augmented Generation) lets LLMs access external information (documents, databases) by retrieving relevant content before generating an answer, improving accuracy and timeliness.

---

## Q5. What are Agents?  
**Agents** are LLM-powered systems that decide which tools to use, perform multi-step reasoning, and take actions to solve complex tasks beyond simple Q&A.

---

## Q6. What are Embeddings?  
**Embeddings** are vector (numeric) representations of text capturing meaning, used to compare similarity, search, and feed into AI workflows like RAG.

---

## Q7. Vector Store / Vector Database?  
A **Vector Store** is a database optimized to store and search embeddings efficiently to find similar content quickly for semantic search and RAG.

---

## Q8. Prompt Engineering  
The art of designing inputs (prompts) to LLMs to get the best outputs. Includes instructions, examples, constraints, and roleplay.

---

## Q9. Fine-Tuning?  
The process of training a pre-trained LLM further on custom data to specialize it for particular tasks, domains, or styles.

---

## Q10. Inference  
The act of running a trained model on new input to generate predictions or outputs.

---

## Q11. What is Token?  
A **token** is a small unit of text (word, part of word, or character) that LLMs process. Models have token limits impacting cost and speed.

---

## Q12. Ollama  
**Ollama** is a platform for running and managing LLMs locally on your machine, providing privacy, low latency, and offline access.

---

# Additional Concepts to Explore  
- Transformer Architecture  
- Attention Mechanism  
- Zero-shot / Few-shot Learning  
- Chatbots & Conversational AI  
- Ethics & Bias in AI  
- Model Distillation  
- Federated Learning  
- Multimodal Models  
- Evaluation Metrics  
- Data Annotation & Labeling  
- Transfer Learning  
- Prompt Tuning / Prefix Tuning  
- API Integration  
- Cost & Latency Optimization  
- Explainability & Interpretability  

---

*This file is for quick reference of AI and LLM-related concepts.*

